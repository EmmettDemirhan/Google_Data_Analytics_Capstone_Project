y = "Total Hours Asleep") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
legend.position = "none"
) +
scale_fill_viridis_d(begin = 0.1, end = 0.9)
# Note: Adjust the plot aesthetics as necessary
# Add a column for day of the week
sleep_day$day_of_week <- weekdays(as.Date(sleep_day$date))
# Create a factor with the levels ordered correctly for days of the week
sleep_day$day_of_week <- factor(sleep_day$day_of_week, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
# Create a summary table for total hours asleep by day of the week, rounded to 2 decimal places
summary_table_sleep <- sleep_day %>%
group_by(day_of_week) %>%
summarize(
Mean = round(mean(total_minutes_asleep / 60), 2),
Median = round(median(total_minutes_asleep / 60), 2),
Min = round(min(total_minutes_asleep / 60), 2),
Max = round(max(total_minutes_asleep / 60), 2),
SD = round(sd(total_minutes_asleep / 60), 2)
) %>%
arrange(match(day_of_week, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")))
# Display the summary table
knitr::kable(summary_table_sleep, caption = "Summary Statistics of Total Hours Asleep by Day of the Week")
# Merge the sleep_day and daily_activity datasets by 'id' and 'date'
merged_data <- merge(sleep_day, daily_activity, by=c('id', 'date'))
# Get a quick overview of the merged dataset to ensure it merged correctly
# glimpse(merged_data)
# Create a scatter plot of total minutes asleep vs. sedentary minutes
ggplot(data=merged_data, aes(x=total_minutes_asleep, y=sedentary_minutes)) +
geom_point(color='darkblue', alpha=0.5) +  # Points are colored dark blue with 50% transparency to reduce overplotting
geom_smooth(method="loess", color="steelblue") +  # Add a loess smoothed trend line in steel blue to highlight the overall trend
labs(title="Relationship between Minutes Asleep and Sedentary Minutes",
x="Total Minutes Asleep",
y="Sedentary Minutes") +  # Add labels and title for clarity
theme_minimal() +  # Use a minimal theme for a clean look
theme(legend.position="bottom",
plot.title = element_text(hjust = 0.5))  # Position the legend at the bottom
# Note that geom_smooth() by default includes a 95% confidence interval around the smooth line
# This shaded area gives an idea of the uncertainty around the trend estimate
correlation_matrix
# Calculate the correlation matrix
correlation_matrix <- cor(combined_data)
# Create a correlation plot
corrplot(correlation_matrix, method = "color", type = "upper",
order = "hclust", tl.cex = 0.6, tl.col = "black",
tl.srt = 45, addCoef.col = "black", number.cex = 0.6)
model <- glm(calories ~ very_active_minutes + mets, data = combined_data, family = gaussian())
summary(model)
# Calculate Cook's distance for each observation
cooks_distance <- cooks.distance(model)
# Plot Cook's distance
plot(cooks_distance, ylab = "Cook's distance", type = "h")
# Identify observations where Cook's distance exceeds a threshold, e.g., 4/(n-k)
# where n is the number of observations and k is the number of predictors
threshold <- 4 / (nrow(combined_data) - length(coef(model)))
outliers <- which(cooks_distance > threshold)
# Review the potential outliers
combined_data[outliers, ]
# Consider removing these outliers
clean_data <- combined_data[-outliers, ]
# Refit the model without outliers
glm_clean <- glm(calories ~ ., data = clean_data, family = gaussian())
# Visualize model diagnostics
par(mfrow = c(2, 2))
plot(glm_clean)
# Calculate Cook's distance for each observation
cooks_distance <- cooks.distance(model)
# Plot Cook's distance
plot(cooks_distance, ylab = "Cook's distance", type = "h")
# Identify observations where Cook's distance exceeds a threshold, e.g., 4/(n-k)
# where n is the number of observations and k is the number of predictors
threshold <- 4 / (nrow(combined_data) - length(coef(model)))
outliers <- which(cooks_distance > threshold)
# Review the potential outliers
combined_data[outliers, ]
# Consider removing these outliers
clean_data <- combined_data[-outliers, ]
# Refit the model without outliers
glm_clean <- glm(calories ~ ., data = clean_data, family = gaussian())
# Visualize model diagnostics
par(mfrow = c(2, 2))
plot(glm_clean)
# Visualize model diagnostics
plot(glm_clean)
# Visualize model diagnostics
par(mfrow = c(2, 3))
plot(glm_clean)
# Visualize model diagnostics
par(mfrow = c(2, ))
# Visualize model diagnostics
par(mfrow = c(2, 2))
plot(glm_clean)
plot(glm_clean)
names(combined_data)
# Scatter Plot for Total Steps vs. METs with a Regression Line
ggplot(data=combined_data, aes(x=total_minutes_asleep, y=sedentary_minutes)) +
geom_point() +
geom_smooth(method="lm") +
labs(title="Total Minutes Asleep vs. Sedentary Minutes", x="Total Minutes Asleep", y="Sedentary Minutes") +
theme_minimal() +
theme(axis.text.x = element_text(angle=0, hjust=1),
plot.title = element_text(hjust = 0.5))
# Scatter Plot for Total Steps vs. Calories with a Regression Line
ggplot(data=daily_activity, aes(x=very_active_minutes, y=calories)) +
geom_point() +
geom_smooth(method="lm") +
labs(title="Very Active Minutes vs. Calories", x="Total Steps", y="Calories") +
theme_minimal() +
theme(axis.text.x = element_text(angle=0, hjust=1),
plot.title = element_text(hjust = 0.5))
Total Steps
# Scatter Plot for Total Steps vs. Calories with a Regression Line
ggplot(data=daily_activity, aes(x=total_steps, y=calories)) +
geom_point() +
geom_smooth(method="lm") +
labs(title="Total Steps vs. Calories", x="Total Steps", y="Calories") +
theme_minimal() +
theme(axis.text.x = element_text(angle=0, hjust=1),
plot.title = element_text(hjust = 0.5))
# Load Libraries
library('tidyverse')
library('janitor')
library('skimr')
library('here')
library('dplyr')
library(tidyr)
library(lubridate)
library(ggplot2)
library(corrplot)
library(knitr)
library(viridis)
library(GGally)
# File names
file_names <- c("dailyActivity_merged.csv", "dailyCalories_merged.csv",
"dailyIntensities_merged.csv", "dailySteps_merged.csv",
"heartrate_seconds_merged.csv", "hourlyCalories_merged.csv",
"hourlyIntensities_merged.csv", "hourlySteps_merged.csv",
"minuteCaloriesNarrow_merged.csv", "minuteCaloriesWide_merged.csv",
"minuteMETsNarrow_merged.csv", "minuteSleep_merged.csv",
"minuteStepsNarrow_merged.csv", "minuteStepsWide_merged.csv",
"sleepDay_merged.csv", "weightLogInfo_merged.csv",
"minuteIntensitiesNarrow_merged.csv", "minuteIntensitiesWide_merged.csv")
# Function to clean dataset names
clean_dataset_name <- function(name) {
name %>%
str_replace_all("([a-z])([A-Z])", "\\1_\\2") %>%  # Insert underscore before a capital letter
tolower() %>%  # Convert to lower case
str_replace_all("__", "_") %>%  # Replace double underscores with a single one
str_trim()  # Trim whitespace
}
# Loop to read each file, assign to a cleaned variable name, and store names in list
datasets <- c()  # Initialize an empty vector to store cleaned dataset names
for (file in file_names) {
var_name <- sub("\\_merged.csv$", "", file)  # Create variable name
cleaned_var_name <- clean_dataset_name(var_name)  # Clean the variable name
file_path <- paste0("Fitabase_Data/", file)  # File path
dataset <- read_csv(file_path) %>% clean_names()  # Read and clean column names
assign(cleaned_var_name, dataset)  # Assign cleaned dataset to cleaned variable name
datasets <- c(datasets, cleaned_var_name)  # Store cleaned dataset name
}
datasets
# Loop through each dataset, print its name, dimensions, and column names
for (dataset in datasets) {
cat("\nDataset name:", dataset, "\n")
data <- get(dataset)
# Display number of rows and columns
cat("Dimensions (Rows x Columns):", dim(data)[1], "x", dim(data)[2], "\n")
# Display the names of the columns
cat("Column Names:", toString(names(data)), "\n")
}
# # Loop through each dataset, print its name and use glimpse to view its structure
# for (dataset in datasets) {
#   cat("\nDataset name:", dataset, "\n")
#   get(dataset) %>% glimpse()
# }
# it is too long to display so I commended this chuck after inspection
# Standardize and convert date columns to a consistent format
convert_and_rename_date <- function(df, old_date_column, new_date_column = "date") {
df <- df %>% rename(!!new_date_column := !!old_date_column)  # Standardize the column name
df[[new_date_column]] <- mdy(df[[new_date_column]])  # Convert to date format
return(df)
}
# Applying the function to convert and rename date formats
daily_activity <- convert_and_rename_date(daily_activity, "activity_date")
daily_calories <- convert_and_rename_date(daily_calories, "activity_day")
daily_intensities <- convert_and_rename_date(daily_intensities, "activity_day")
daily_steps <- convert_and_rename_date(daily_steps, "activity_day")
# Function to convert datetime columns to a consistent date format and standardize the name
convert_and_rename_datetime_to_date <- function(df, old_datetime_column, new_date_column = "date") {
df <- df %>% rename(!!new_date_column := !!old_datetime_column)  # Standardize the column name
df[[new_date_column]] <- mdy(sub(" .*", "", df[[new_date_column]]))  # Convert datetime to date format
return(df)
}
# Applying the function to convert datetime to date formats and rename
sleep_day <- convert_and_rename_datetime_to_date(sleep_day, "sleep_day")
weight_log_info <- convert_and_rename_datetime_to_date(weight_log_info, "date")
# Initialize a data frame to store results
unique_id_counts <- data.frame(dataset_name = character(), unique_ids = numeric(), stringsAsFactors = FALSE)
# Loop to check unique IDs in all datasets
for (dataset_name in datasets) {
dataset <- get(dataset_name)
unique_ids <- n_distinct(dataset$id)
unique_id_counts <- rbind(unique_id_counts, data.frame(dataset_name = dataset_name, unique_ids = unique_ids))
}
# Display the results
print(unique_id_counts)
# Initialize a data frame to store results
duplicate_counts <- data.frame(dataset_name = character(), number_of_duplicates = integer(), stringsAsFactors = FALSE)
# Loop to check for duplicates in all datasets
for (dataset_name in datasets) {
dataset <- get(dataset_name)
duplicate_count <- sum(duplicated(dataset))
duplicate_counts <- rbind(duplicate_counts, data.frame(dataset_name = dataset_name, number_of_duplicates = duplicate_count))
}
# Display the results
print(duplicate_counts)
# Initialize a data frame to store results post-removal
post_removal_duplicate_counts <- data.frame(dataset_name = character(), number_of_duplicates_post_removal = integer(), stringsAsFactors = FALSE)
# Loop to remove duplicates from all datasets and check duplicates after removal
for (dataset_name in datasets) {
dataset <- unique(get(dataset_name))
assign(dataset_name, dataset)
duplicate_count_post_removal <- sum(duplicated(dataset))
post_removal_duplicate_counts <- rbind(post_removal_duplicate_counts, data.frame(dataset_name = dataset_name, number_of_duplicates_post_removal = duplicate_count_post_removal))
}
# Display the results
print(post_removal_duplicate_counts)
# Initialize a data frame to store results
unique_day_counts <- data.frame(dataset_name = character(), number_of_unique_days = integer(), stringsAsFactors = FALSE)
# Loop to check unique days in all datasets
for (dataset_name in datasets) {
dataset <- get(dataset_name)
if("date" %in% names(dataset)) {
unique_days <- length(unique(dataset$date))
unique_day_counts <- rbind(unique_day_counts, data.frame(dataset_name = dataset_name, number_of_unique_days = unique_days))
} else {
unique_day_counts <- rbind(unique_day_counts, data.frame(dataset_name = dataset_name, number_of_unique_days = NA_integer_))
}
}
# Display the results
print(unique_day_counts)
# Assuming 'value' column in minute_sleep indicates minutes asleep
daily_sleep_aggregated <- minute_sleep %>%
mutate(date = mdy_hms(date) %>% as.Date()) %>%
group_by(id, date) %>%
summarize(total_minutes_asleep = sum(value, na.rm = TRUE), .groups = "drop")
# Joining with sleep_day dataset
comparison_df <- sleep_day %>%
full_join(daily_sleep_aggregated, by = c("id", "date")) %>%
mutate(difference = total_minutes_asleep.x - total_minutes_asleep.y)
# Checking differences
head(comparison_df) %>%
select(id, date, total_minutes_asleep.x, total_minutes_asleep.y, difference) %>%
arrange(desc(abs(difference)))
# Create the Plot
ggplot(comparison_df, aes(x = total_minutes_asleep.x, y = total_minutes_asleep.y)) +
geom_point() +
labs(x = "Total Minutes Asleep (sleep_day)",
y = "Total Minutes Asleep (daily_sleep_aggregated)",
title = "Comparison of Sleep Data") +
theme_minimal() +
geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "blue") +
theme(plot.title = element_text(hjust = 0.5))  # Centering the title
# so checking duplicates
print(paste("Number of duplicates in daily_sleep_aggregated:", sum(duplicated(daily_sleep_aggregated))))
# No duplicates, checking how many days I got
# Counting unique days per id
unique_days_sleep <- length(unique(daily_sleep_aggregated$date))
print(paste("Number of unique days:", unique_days_sleep))
# Convert 'activity_minute' from character to datetime format
minute_mets_narrow$activity_minute <- as.POSIXct(minute_mets_narrow$activity_minute, format="%m/%d/%Y %I:%M:%S %p")
# Extract date from 'activity_minute'
minute_mets_narrow$date <- as.Date(minute_mets_narrow$activity_minute)
# Aggregate METs data to daily totals
daily_mets <- aggregate(me_ts ~ id + date, minute_mets_narrow, sum)
# Renameing mets columns as mets
daily_mets <- daily_mets %>% rename(mets = me_ts)
# Interestingly 962 columns which is higher than 940 as in daily_activities
# so checking duplicates
print(paste("Number of duplicates in date:", sum(duplicated(daily_mets))))
# No duplicates, checking how many days I got
# Counting unique days per id
unique_days <- length(unique(daily_mets$date))
print(paste("Number of unique days:", unique_days))
# Create a scatter plot to see difference between tracker_distance and total_distance
plot(daily_activity$tracker_distance, daily_activity$total_distance,
xlab = "Tracker Distance", ylab = "Total Distance",
main = "Scatter Plot of Total Steps vs. Total Distance")
# Removing tracker_distance
daily_activity <- daily_activity %>% select(-tracker_distance)
glimpse(daily_activity)
# Loop through each dataset and check for missing values
for (dataset in datasets) {
data <- get(dataset)
# Calculate the sum of missing values for each column
missing_values <- sapply(data, function(x) sum(is.na(x)))
# Filter out columns with no missing values
missing_values <- missing_values[missing_values > 0]
# Check if there are any missing values in the dataset
if (length(missing_values) > 0) {
# Create a summary string for missing values
missing_summary_string <- paste("Dataset name:", dataset, "\n",
"Missing Values Summary:\n",
toString(sprintf("%s: %d", names(missing_values), missing_values)),
sep = "\n")
# Print the summary string
cat(missing_summary_string, "\n\n")
}
}
# Exclude 'id', 'date', and 'day_of_week' from the analysis
selected_columns <- setdiff(names(daily_activity), c("id", "date", "day_of_week"))
# Create a summary table for these variables
summary_table <- daily_activity %>%
select(all_of(selected_columns)) %>%
summarise(across(everything(),
list(Mean = ~round(mean(.), 2),
Median = ~round(median(.), 2),
Min = ~round(min(.), 2),
Max = ~round(max(.), 2),
SD = ~round(sd(.), 2)),
.names = "{col}_{.fn}")) %>%
pivot_longer(cols = everything(),
names_to = c("Variable", ".value"),
names_pattern = "(.*)_(.*)")
# Display the summary table
knitr::kable(summary_table, caption = "Summary Statistics of Daily Activity Variables")
# Merging with aggregated daily METs data
combined_data <- merge(daily_activity, daily_mets, by = c("id", "date"))
# Merging with sleep data
combined_data <- merge(combined_data, sleep_day, by = c("id", "date"))
# head(combined_data)
# Select features based on domain knowledge and multicollinearity considerations
combined_data <- combined_data %>%
select(calories, total_steps, very_active_minutes, fairly_active_minutes, lightly_active_minutes, sedentary_minutes, mets, total_minutes_asleep)
head(combined_data)
# Calculate the correlation matrix
correlation_matrix <- cor(combined_data)
# Create a correlation plot
corrplot(correlation_matrix, method = "color", type = "upper",
order = "hclust", tl.cex = 0.6, tl.col = "black",
tl.srt = 45, addCoef.col = "black", number.cex = 0.6)
# Scatter Plot for Total Steps vs. METs with a Regression Line
ggplot(data=combined_data, aes(x=total_steps, y=mets)) +
geom_point() +
geom_smooth(method="lm") +
labs(title="Total Steps vs. METs", x="Total Steps", y="METs") +
theme_minimal() +
theme(axis.text.x = element_text(angle=0, hjust=1),
plot.title = element_text(hjust = 0.5))
# Scatter Plot for Total Steps vs. Calories with a Regression Line
ggplot(data=daily_activity, aes(x=total_steps, y=calories)) +
geom_point() +
geom_smooth(method="lm") +
labs(title="Total Steps vs. Calories", x="Total Steps", y="Calories") +
theme_minimal() +
theme(axis.text.x = element_text(angle=0, hjust=1),
plot.title = element_text(hjust = 0.5))
# Scatter Plot for Total Steps vs. METs with a Regression Line
ggplot(data=combined_data, aes(x=total_minutes_asleep, y=sedentary_minutes)) +
geom_point() +
geom_smooth(method="lm") +
labs(title="Total Minutes Asleep vs. Sedentary Minutes", x="Total Minutes Asleep", y="Sedentary Minutes") +
theme_minimal() +
theme(axis.text.x = element_text(angle=0, hjust=1),
plot.title = element_text(hjust = 0.5))
# Extract day of the week from the date
daily_activity$day_of_week <- weekdays(daily_activity$date)
# Create a factor with the levels ordered correctly for days of the week
daily_activity$day_of_week <- factor(daily_activity$day_of_week, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
# Exclude the last date from the dataset
filtered_daily_activity <- daily_activity %>%
filter(date != max(date))
# Create a violin plot with data points and median points
ggplot(filtered_daily_activity, aes(x = day_of_week, y = total_steps)) +
geom_violin(aes(fill = day_of_week), trim = FALSE, alpha = 0.4) +
geom_jitter(aes(color = day_of_week), width = 0.15, size = 2) +
stat_summary(fun=median, geom="point", size=3, color="black", shape=18) + # Add median points
labs(title = "Violin Plot of Total Steps by Day of the Week",
x = "Day of the Week",
y = "Total Steps") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
plot.title.position = "plot",
legend.position = "none"  # Hides the legend
) +
scale_fill_viridis_d(option = "C", end = 0.9, begin = 0.1, name = NULL) +
scale_color_viridis_d(option = "C", end = 0.9, begin = 0.1, name = NULL)
# Create a summary table
summary_table <- daily_activity %>%
group_by(day_of_week) %>%
summarize(
Mean = round(mean(total_steps), 2),
Median = round(median(total_steps), 2),
Min = round(min(total_steps), 2),
Max = round(max(total_steps), 2),
SD = round(sd(total_steps), 2)
) %>%
arrange(match(day_of_week, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")))
# Display the table using knitr
knitr::kable(summary_table, caption = "Summary Statistics of Total Steps by Day of the Week")
# Calculate summary statistics for heart rate values for each ID
summary_table_hr_by_id <- heartrate_seconds %>%
group_by(id) %>%
summarise(
Mean = round(mean(value), 2),
Median = round(median(value), 2),
Min = round(min(value), 2),
Max = round(max(value), 2),
SD = round(sd(value), 2)
) %>%
ungroup()  # Remove grouping
# Display the summary table
knitr::kable(summary_table_hr_by_id, caption = "Summary Statistics of Heart Rate by ID")
# Boxplot for each ID
ggplot(heartrate_seconds, aes(x = factor(id), y = value)) +
geom_boxplot() +
labs(title = "Heart Rate Distribution by ID",
x = "ID",
y = "Heart Rate (bpm)") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 30, hjust = 1),
plot.title = element_text(hjust = 0.5))   # Rotate x-axis labels for better readability
# Convert the activity_hour column to datetime
hourly_intensities$activity_hour <- as.POSIXct(hourly_intensities$activity_hour, format="%m/%d/%Y %I:%M:%S %p")
# Extract the day of the week and hour
hourly_intensities$day_of_week <- weekdays(hourly_intensities$activity_hour)
hourly_intensities$hour <- format(hourly_intensities$activity_hour, "%H")
# Aggregate to get average intensity per hour for each day of the week
average_intensity_by_hour <- hourly_intensities %>%
group_by(day_of_week, hour) %>%
summarise(average_intensity = mean(average_intensity, na.rm = TRUE)) %>%
ungroup()
# Reorder the days of the week
average_intensity_by_hour$day_of_week <- factor(average_intensity_by_hour$day_of_week,
levels = c( "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday","Sunday"))
# Create the plot with a single color gradient and numbers on boxes
ggplot(average_intensity_by_hour, aes(x=day_of_week, y=hour, fill=average_intensity)) +
geom_tile() +
geom_text(aes(label = sprintf("%.2f", average_intensity)), color = "black", size = 3) +  # Add numbers on boxes, rounded to two decimals
scale_fill_gradient(low = "lightblue", high = "darkblue", name = "Average Intensity") +
scale_x_discrete(limits = c( "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")) +  # Adjust x-axis for discrete values
scale_y_discrete(breaks = unique(average_intensity_by_hour$hour)) +  # Adjust y-axis dimensions
labs(title="Average Intensity by Day of the Week and Hour",
x="Day of the Week",
y="Hour of the Day") +
theme_minimal() +
theme(axis.text.x = element_text(angle=0, hjust=1),
plot.title = element_text(hjust = 0.5))
# Boxplot for total minutes asleep
ggplot(sleep_day, aes(x = factor(id), y = total_minutes_asleep)) +
geom_boxplot() +
labs(title = "Total Minutes Asleep Distribution by ID",
x = "ID",
y = "Total Minutes Asleep") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1),
plot.title = element_text(hjust = 0.5))
# Extract day of the week from the date
sleep_day$day_of_week <- weekdays(sleep_day$date)
# Create a factor with the levels ordered correctly for days of the week
sleep_day$day_of_week <- factor(sleep_day$day_of_week, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
# Create a violin plot for total hours asleep by day of the week
ggplot(sleep_day, aes(x = day_of_week, y = total_minutes_asleep/60, fill = day_of_week)) +
geom_violin(trim = FALSE, alpha = 0.4) +
geom_jitter(width = 0.15, size = 2) +
stat_summary(fun = median, geom = "point", size = 3, color = "white", shape = 18) + # Add median points
labs(title = "Violin Plot of Total Hours Asleep by Day of the Week",
x = "Day of the Week",
y = "Total Hours Asleep") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
legend.position = "none"
) +
scale_fill_viridis_d(begin = 0.1, end = 0.9)
# Note: Adjust the plot aesthetics as necessary
# Add a column for day of the week
sleep_day$day_of_week <- weekdays(as.Date(sleep_day$date))
# Create a factor with the levels ordered correctly for days of the week
sleep_day$day_of_week <- factor(sleep_day$day_of_week, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
# Create a summary table for total hours asleep by day of the week, rounded to 2 decimal places
summary_table_sleep <- sleep_day %>%
group_by(day_of_week) %>%
summarize(
Mean = round(mean(total_minutes_asleep / 60), 2),
Median = round(median(total_minutes_asleep / 60), 2),
Min = round(min(total_minutes_asleep / 60), 2),
Max = round(max(total_minutes_asleep / 60), 2),
SD = round(sd(total_minutes_asleep / 60), 2)
) %>%
arrange(match(day_of_week, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")))
# Display the summary table
knitr::kable(summary_table_sleep, caption = "Summary Statistics of Total Hours Asleep by Day of the Week")
# Merge the sleep_day and daily_activity datasets by 'id' and 'date'
merged_data <- merge(sleep_day, daily_activity, by=c('id', 'date'))
# Get a quick overview of the merged dataset to ensure it merged correctly
# glimpse(merged_data)
# Create a scatter plot of total minutes asleep vs. sedentary minutes
ggplot(data=merged_data, aes(x=total_minutes_asleep, y=sedentary_minutes)) +
geom_point(color='darkblue', alpha=0.5) +  # Points are colored dark blue with 50% transparency to reduce overplotting
geom_smooth(method="loess", color="steelblue") +  # Add a loess smoothed trend line in steel blue to highlight the overall trend
labs(title="Relationship between Minutes Asleep and Sedentary Minutes",
x="Total Minutes Asleep",
y="Sedentary Minutes") +  # Add labels and title for clarity
theme_minimal() +  # Use a minimal theme for a clean look
theme(legend.position="bottom",
plot.title = element_text(hjust = 0.5))  # Position the legend at the bottom
# Note that geom_smooth() by default includes a 95% confidence interval around the smooth line
# This shaded area gives an idea of the uncertainty around the trend estimate
